<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/"><channel><title>Home on Louis Dupont</title><link>https://louis-dupont.github.io/Blog/</link><description>Recent content in Home on Louis Dupont</description><generator>Hugo -- 0.145.0</generator><language>en-us</language><lastBuildDate>Tue, 18 Mar 2025 15:42:04 +0100</lastBuildDate><atom:link href="https://louis-dupont.github.io/Blog/index.xml" rel="self" type="application/rss+xml"/><item><title>Unblock Your AI (For Good)</title><link>https://louis-dupont.github.io/Blog/articles/error-analysis-in-practice/</link><pubDate>Tue, 18 Mar 2025 15:42:04 +0100</pubDate><guid>https://louis-dupont.github.io/Blog/articles/error-analysis-in-practice/</guid><description>&lt;p>Many teams I‚Äôve worked with start out making rapid progress with their AI - usually a RAG system. At first, iteration is fast. Each tweak makes a visible difference. But then, they hit a plateau.&lt;/p>
&lt;p>&lt;strong>Changes don‚Äôt seem to make a clear impact anymore&lt;/strong>. Some changes even backfire. The AI isn&amp;rsquo;t broken, but it‚Äôs no longer clear what to fix‚Äîor even how to tell if it‚Äôs improving at all.&lt;/p>
&lt;h2 id="when-metrics-stop-making-sense">When Metrics Stop Making Sense&lt;/h2>
&lt;p>That‚Äôs when most teams turn to metrics. And &lt;strong>that‚Äôs where things usually go wrong.&lt;/strong>&lt;/p></description></item><item><title>How to Fail your AI Project ‚Äì Like I Did</title><link>https://louis-dupont.github.io/Blog/articles/my-realisation-moment/</link><pubDate>Wed, 12 Mar 2025 15:59:10 +0100</pubDate><guid>https://louis-dupont.github.io/Blog/articles/my-realisation-moment/</guid><description>&lt;p>A few years ago, I worked on my first Generative AI project: a customer-facing AI assistant. The company had unique customer data and believed AI could transform it into a highly personalized, valuable chatbot.&lt;/p>
&lt;p>We built a prototype fast. Our users were excited about the first demo.&lt;/p>
&lt;h2 id="our-first-big-mistake">Our First Big Mistake&lt;/h2>
&lt;p>But there was a catch: we had almost no access to real users. With so few user tests, we had to rely on ourselves‚Äîwe became our own test users.&lt;/p></description></item><item><title>ü™§ The Chatbot Trap - Why Your LLM Project Is Stuck After the ‚ÄúWow Moment"</title><link>https://louis-dupont.github.io/Blog/archive/the-chatbot-trap/</link><pubDate>Fri, 07 Mar 2025 16:22:38 +0100</pubDate><guid>https://louis-dupont.github.io/Blog/archive/the-chatbot-trap/</guid><description>&lt;p>&lt;em>Your LLM prototype amazed everyone‚Äîuntil it didn&amp;rsquo;t. Now it&amp;rsquo;s stuck, and no one&amp;rsquo;s using it. Here&amp;rsquo;s why.&lt;/em>&lt;/p>
&lt;p>When most companies experiment with AI, &lt;strong>the go-to application is a chatbot&lt;/strong>. It&amp;rsquo;s intuitive, it looks impressive, and it feels like magic. But here&amp;rsquo;s the cold, hard truth: &lt;strong>chatbots are why most LLM projects fail.&lt;/strong>&lt;/p>
&lt;p>I&amp;rsquo;ve seen it happen countless times. The team builds a chatbot to ‚Äúharness AI,‚Äù and at first, it wows everyone. But then the cracks start to show:&lt;/p></description></item><item><title>DO NOT use these LLM Metrics ‚õî And what to do instead!</title><link>https://louis-dupont.github.io/Blog/archive/eval-metrics-to-avoid/</link><pubDate>Sat, 15 Feb 2025 11:00:00 +0100</pubDate><guid>https://louis-dupont.github.io/Blog/archive/eval-metrics-to-avoid/</guid><description>&lt;p>In two words: &lt;strong>Generalist LLM metrics are more of a danger than an opportunity.&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>&lt;strong>NEVER&lt;/strong> start with them.&lt;/li>
&lt;li>Use them only as a &lt;strong>last resort&lt;/strong>‚Äîand even then, with strict guidelines!&lt;/li>
&lt;/ul>
&lt;h3 id="so-what-are-these-vague-generic-metrics">So what are these vague, generic metrics?&lt;/h3>
&lt;ul>
&lt;li>Helpfulness&lt;/li>
&lt;li>Conciseness&lt;/li>
&lt;li>Tone&lt;/li>
&lt;li>Personalisation&lt;/li>
&lt;li>‚Ä¶ and more!&lt;/li>
&lt;/ul>
&lt;p>But what&amp;rsquo;s so wrong with them?&lt;/p>
&lt;h2 id="these-metrics-lack-real-meaning">These Metrics Lack Real Meaning&lt;/h2>
&lt;p>The biggest problem? They&amp;rsquo;re designed to evaluate an &lt;strong>LLM in general&lt;/strong>, not a &lt;strong>specific use case&lt;/strong>.&lt;/p></description></item><item><title>Error Analysis üîß Stop Guessing, Start Fixing AI Models</title><link>https://louis-dupont.github.io/Blog/archive/error-analys-intro/</link><pubDate>Fri, 14 Feb 2025 12:00:00 +0100</pubDate><guid>https://louis-dupont.github.io/Blog/archive/error-analys-intro/</guid><description>Error analysis is about digging deep into why something isn&amp;#39;t working - to learn from it.</description></item><item><title>Evaluate your LLM! Ok, but what's next? ü§î</title><link>https://louis-dupont.github.io/Blog/archive/evaluate-chatbot-whatnext/</link><pubDate>Thu, 02 Jan 2025 10:00:00 +0100</pubDate><guid>https://louis-dupont.github.io/Blog/archive/evaluate-chatbot-whatnext/</guid><description>&lt;p>&lt;strong>Everyone say you need to Evaluate your LLM. You just did it. Now what? ü§∑‚Äç‚ôÇÔ∏è&lt;/strong>&lt;/p>
&lt;p>You got a score. Great. Now, here&amp;rsquo;s the trap:&lt;/p>
&lt;p>You either:&lt;/p>
&lt;ul>
&lt;li>&lt;strong>Trust it.&lt;/strong> (&lt;em>&amp;ldquo;Nice, let&amp;rsquo;s ship!&amp;rdquo;&lt;/em>)&lt;/li>
&lt;li>&lt;strong>Chase a better one.&lt;/strong> (&lt;em>&amp;ldquo;Tweak some stuff and re-run!&amp;rdquo;&lt;/em>)&lt;/li>
&lt;/ul>
&lt;p>Both are &lt;strong>horrible ideas.&lt;/strong>&lt;/p>
&lt;h2 id="step-1-stop-staring-at-numbers">&lt;strong>Step 1: Stop staring at numbers.&lt;/strong>&lt;/h2>
&lt;p>Numbers feel scientific, but &lt;strong>they lie all the time.&lt;/strong>&lt;/p>
&lt;p>Before doing anything, look at actual examples. &lt;strong>What&amp;rsquo;s failing?&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>Bad output? &lt;strong>Fix the model.&lt;/strong>&lt;/li>
&lt;li>Good output but bad score? &lt;strong>Fix the eval.&lt;/strong>&lt;/li>
&lt;li>Both wrong? &lt;strong>You&amp;rsquo;ve got bigger problems.&lt;/strong>&lt;/li>
&lt;/ul>
&lt;h2 id="step-2-solve-the-right-problem">&lt;strong>Step 2: Solve the right problem.&lt;/strong>&lt;/h2>
&lt;p>If your &lt;strong>model sucks&lt;/strong>, tweak:&lt;/p></description></item><item><title>LLM Evals - The Trap No One's Telling You üêî</title><link>https://louis-dupont.github.io/Blog/archive/eval-trap/</link><pubDate>Thu, 02 Jan 2025 10:00:00 +0100</pubDate><guid>https://louis-dupont.github.io/Blog/archive/eval-trap/</guid><description>&lt;p>We hear it more and more: ‚ÄòUse LLM Evaluations to guide your AI project.&amp;rsquo; And for a good reason‚Äîmetrics are essential.&lt;/p>
&lt;p>&lt;strong>Yet, there&amp;rsquo;s a trap nobody talks about&amp;hellip;&lt;/strong>&lt;/p>
&lt;p>Let&amp;rsquo;s say you have a chatbot and want to introduce metrics. You find tools that compute metrics like &amp;lsquo;Helpfulness&amp;rsquo;, &amp;lsquo;Conciseness&amp;rsquo;, and &amp;lsquo;Completeness&amp;rsquo;.
Sounds great‚Äîthey promise to optimise your user&amp;rsquo;s experience. Right?&lt;/p>
&lt;p>Truth is, their correlation to real business value is often unclear. Is this really what your user cares about ? Will this increase adoption ?&lt;/p></description></item><item><title>üìâ Why Improving Your AI Model Is Killing Your Project's Success</title><link>https://louis-dupont.github.io/Blog/archive/dont-improve-ai/</link><pubDate>Wed, 01 Jan 2025 16:22:38 +0100</pubDate><guid>https://louis-dupont.github.io/Blog/archive/dont-improve-ai/</guid><description>&lt;p>&lt;em>What if improving your AI model is the very thing holding your project back?&lt;/em>&lt;/p>
&lt;p>You&amp;rsquo;ve spent weeks fine-tuning it‚Äîpolishing every detail, boosting accuracy, solving edge cases. Yet, adoption hasn&amp;rsquo;t moved. &lt;em>Frustrating?&lt;/em> You&amp;rsquo;re not alone‚Äî&lt;strong>this is a trap many AI teams fall into.&lt;/strong>&lt;/p>
&lt;p>The problem isn&amp;rsquo;t that AI isn&amp;rsquo;t ready. It&amp;rsquo;s that the way we approach AI makes us feel productive while ignoring the real challenge: solving critical user needs.&lt;/p>
&lt;p>Let&amp;rsquo;s break down why this happens‚Äîand how you can escape the trap.&lt;/p></description></item><item><title>Turn Your Broken Chatbot into Your Biggest Asset! üè¶</title><link>https://louis-dupont.github.io/Blog/archive/leverage-chatbot/</link><pubDate>Sat, 28 Dec 2024 16:22:38 +0100</pubDate><guid>https://louis-dupont.github.io/Blog/archive/leverage-chatbot/</guid><description>&lt;p>You launched your chatbot, and‚Ä¶ well, it&amp;rsquo;s not going as planned. Users are confused, workflows feel disjointed, and your team&amp;rsquo;s enthusiasm is quickly waning. Sound familiar?&lt;/p>
&lt;p>Here&amp;rsquo;s the good news: your chatbot isn&amp;rsquo;t just failing‚Äîit&amp;rsquo;s revealing what matters.&lt;/p>
&lt;p>&lt;strong>Every awkward interaction or frustrated user is a clue&lt;/strong>. The gaps in your bot&amp;rsquo;s performance mirror the gaps in your understanding of user needs. And those gaps? They&amp;rsquo;re opportunities.&lt;/p>
&lt;p>In my &lt;a href="the-chatbot-trap.md">recent post&lt;/a>, I explained why so many AI projects fall short‚Äîteams jump straight into building chatbots without asking whether they&amp;rsquo;re the right solution for the problem at hand. Often, they&amp;rsquo;re not. But even a ‚Äúfailing‚Äù chatbot can become a powerful diagnostic tool for understanding user needs more deeply.&lt;/p></description></item><item><title>ü§∑‚Äç‚ôÇÔ∏è ModernBERT Is Here - and It's Not Just Another LLM Update</title><link>https://louis-dupont.github.io/Blog/archive/modernbert/</link><pubDate>Fri, 20 Dec 2024 16:22:38 +0100</pubDate><guid>https://louis-dupont.github.io/Blog/archive/modernbert/</guid><description>&lt;p>BERT is back - and this time, it&amp;rsquo;s &lt;strong>faster, smarter, and built for the tasks that matter.&lt;/strong>&lt;/p>
&lt;p>If you&amp;rsquo;re working on &lt;strong>retrieval&lt;/strong>, &lt;strong>classification&lt;/strong>, or &lt;strong>code search&lt;/strong>, encoder models like BERT have likely been your go-to. Generative LLMs may grab headlines, but &lt;strong>when it comes to focused, production-ready AI tasks, BERT still shines&lt;/strong>.&lt;/p>
&lt;p>Earlier this year, I ran an experiment comparing models on a real-world task‚Äîanalyzing product reviews. The results were eye-opening:&lt;/p></description></item><item><title>Consulting</title><link>https://louis-dupont.github.io/Blog/work-with-me/</link><pubDate>Mon, 20 May 2024 00:00:00 +0000</pubDate><guid>https://louis-dupont.github.io/Blog/work-with-me/</guid><description>AI doesn&amp;#39;t improve simply by doing more. It improves when you have clarity‚Äîwhen you know exactly what&amp;#39;s limiting progress, and exactly how to move forward. That&amp;#39;s what I do.</description></item></channel></rss>