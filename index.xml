<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/"><channel><title>Home on Louis Dupont</title><link>https://louis-dupont.github.io/Blog/</link><description>Recent content in Home on Louis Dupont</description><generator>Hugo -- 0.145.0</generator><language>en-us</language><lastBuildDate>Fri, 07 Mar 2025 16:22:38 +0100</lastBuildDate><atom:link href="https://louis-dupont.github.io/Blog/index.xml" rel="self" type="application/rss+xml"/><item><title>ğŸª¤ The Chatbot Trap - Why Your LLM Project Is Stuck After the â€œWow Moment"</title><link>https://louis-dupont.github.io/Blog/articles/the-chatbot-trap/</link><pubDate>Fri, 07 Mar 2025 16:22:38 +0100</pubDate><guid>https://louis-dupont.github.io/Blog/articles/the-chatbot-trap/</guid><description>&lt;p>&lt;em>Your LLM prototype amazed everyoneâ€”until it didnâ€™t. Now itâ€™s stuck, and no oneâ€™s using it. Hereâ€™s why.&lt;/em>&lt;/p>
&lt;p>When most companies experiment with AI, &lt;strong>the go-to application is a chatbot&lt;/strong>. Itâ€™s intuitive, it looks impressive, and it feels like magic. But hereâ€™s the cold, hard truth: &lt;strong>chatbots are why most LLM projects fail.&lt;/strong>&lt;/p>
&lt;p>Iâ€™ve seen it happen countless times. The team builds a chatbot to â€œharness AI,â€ and at first, it wows everyone. But then the cracks start to show:&lt;/p></description></item><item><title>DO NOT use these LLM Metrics â›” And what to do instead!</title><link>https://louis-dupont.github.io/Blog/articles/eval-metrics-to-avoid/</link><pubDate>Sat, 15 Feb 2025 11:00:00 +0100</pubDate><guid>https://louis-dupont.github.io/Blog/articles/eval-metrics-to-avoid/</guid><description>&lt;p>In two words: &lt;strong>Generalist LLM metrics are more of a danger than an opportunity.&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>&lt;strong>NEVER&lt;/strong> start with them.&lt;/li>
&lt;li>Use them only as a &lt;strong>last resort&lt;/strong>â€”and even then, with strict guidelines!&lt;/li>
&lt;/ul>
&lt;h3 id="so-what-are-these-vague-generic-metrics">So what are these vague, generic metrics?&lt;/h3>
&lt;ul>
&lt;li>Helpfulness&lt;/li>
&lt;li>Conciseness&lt;/li>
&lt;li>Tone&lt;/li>
&lt;li>Personalisation&lt;/li>
&lt;li>â€¦ and more!&lt;/li>
&lt;/ul>
&lt;p>But whatâ€™s so wrong with them?&lt;/p>
&lt;h2 id="these-metrics-lack-real-meaning">These Metrics Lack Real Meaning&lt;/h2>
&lt;p>The biggest problem? Theyâ€™re designed to evaluate an &lt;strong>LLM in general&lt;/strong>, not a &lt;strong>specific use case&lt;/strong>.&lt;/p></description></item><item><title>Error Analysis ğŸ”§ Stop Guessing, Start Fixing AI Models</title><link>https://louis-dupont.github.io/Blog/articles/error-analys-intro/</link><pubDate>Fri, 14 Feb 2025 12:00:00 +0100</pubDate><guid>https://louis-dupont.github.io/Blog/articles/error-analys-intro/</guid><description>&lt;p>Error analysis is about digging deep into &lt;em>why&lt;/em> something isnâ€™t working - to learn from it. It might sound obvious, but it&amp;rsquo;s shockingly underused, especially where it matters most: AI development.&lt;/p>
&lt;p>Let&amp;rsquo;s explore what it is through an example&lt;/p>
&lt;h2 id="cats-or-dogs-">Cats or Dogs ?&lt;/h2>
&lt;p>&lt;em>I&amp;rsquo;m skipping many details that may hurt Data Scientists for the sake of simplicity.&lt;/em>&lt;/p>
&lt;p>Say you have 200 images to classify as either cats or dogs. You build an AI and get &lt;strong>78% accuracy&lt;/strong> - not great. We need to do better. But how?&lt;/p></description></item><item><title>Evaluate your LLM! Ok, but what's next? ğŸ¤”</title><link>https://louis-dupont.github.io/Blog/articles/evaluate-chatbot-whatnext/</link><pubDate>Thu, 02 Jan 2025 10:00:00 +0100</pubDate><guid>https://louis-dupont.github.io/Blog/articles/evaluate-chatbot-whatnext/</guid><description>&lt;p>&lt;strong>Everyone say you need to Evaluate your LLM. You just did it. Now what? ğŸ¤·â€â™‚ï¸&lt;/strong>&lt;/p>
&lt;p>You got a score. Great. Now, hereâ€™s the trap:&lt;/p>
&lt;p>You either:&lt;/p>
&lt;ul>
&lt;li>&lt;strong>Trust it.&lt;/strong> (&lt;em>&amp;ldquo;Nice, let&amp;rsquo;s ship!&amp;rdquo;&lt;/em>)&lt;/li>
&lt;li>&lt;strong>Chase a better one.&lt;/strong> (&lt;em>&amp;ldquo;Tweak some stuff and re-run!&amp;rdquo;&lt;/em>)&lt;/li>
&lt;/ul>
&lt;p>Both are &lt;strong>horrible ideas.&lt;/strong>&lt;/p>
&lt;h2 id="step-1-stop-staring-at-numbers">&lt;strong>Step 1: Stop staring at numbers.&lt;/strong>&lt;/h2>
&lt;p>Numbers feel scientific, but &lt;strong>they lie all the time.&lt;/strong>&lt;/p>
&lt;p>Before doing anything, look at actual examples. &lt;strong>Whatâ€™s failing?&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>Bad output? &lt;strong>Fix the model.&lt;/strong>&lt;/li>
&lt;li>Good output but bad score? &lt;strong>Fix the eval.&lt;/strong>&lt;/li>
&lt;li>Both wrong? &lt;strong>Youâ€™ve got bigger problems.&lt;/strong>&lt;/li>
&lt;/ul>
&lt;h2 id="step-2-solve-the-right-problem">&lt;strong>Step 2: Solve the right problem.&lt;/strong>&lt;/h2>
&lt;p>If your &lt;strong>model sucks&lt;/strong>, tweak:&lt;/p></description></item><item><title>LLM Evals - The Trap No Oneâ€™s Telling You ğŸ”</title><link>https://louis-dupont.github.io/Blog/articles/eval-trap/</link><pubDate>Thu, 02 Jan 2025 10:00:00 +0100</pubDate><guid>https://louis-dupont.github.io/Blog/articles/eval-trap/</guid><description>&lt;p>We hear it more and more: â€˜Use LLM Evaluations to guide your AI project.â€™ And for a good reasonâ€”metrics are essential.&lt;/p>
&lt;p>&lt;strong>Yet, thereâ€™s a trap nobody talks about&amp;hellip;&lt;/strong>&lt;/p>
&lt;p>Letâ€™s say you have a chatbot and want to introduce metrics. You find tools that compute metrics like &amp;lsquo;Helpfulness&amp;rsquo;, &amp;lsquo;Conciseness&amp;rsquo;, and &amp;lsquo;Completeness&amp;rsquo;.
Sounds greatâ€”they promise to optimise your userâ€™s experience. Right?&lt;/p>
&lt;p>Truth is, their correlation to real business value is often unclear. Is this really what your user cares about ? Will this increase adoption ?&lt;/p></description></item><item><title>ğŸ“‰ Why Improving Your AI Model Is Killing Your Project's Success</title><link>https://louis-dupont.github.io/Blog/articles/dont-improve-ai/</link><pubDate>Wed, 01 Jan 2025 16:22:38 +0100</pubDate><guid>https://louis-dupont.github.io/Blog/articles/dont-improve-ai/</guid><description>&lt;p>&lt;em>What if improving your AI model is the very thing holding your project back?&lt;/em>&lt;/p>
&lt;p>You&amp;rsquo;ve spent weeks fine-tuning itâ€”polishing every detail, boosting accuracy, solving edge cases. Yet, adoption hasn&amp;rsquo;t moved. &lt;em>Frustrating?&lt;/em> You&amp;rsquo;re not aloneâ€”&lt;strong>this is a trap many AI teams fall into.&lt;/strong>&lt;/p>
&lt;p>The problem isn&amp;rsquo;t that AI isn&amp;rsquo;t ready. It&amp;rsquo;s that the way we approach AI makes us feel productive while ignoring the real challenge: solving critical user needs.&lt;/p>
&lt;p>Let&amp;rsquo;s break down why this happensâ€”and how you can escape the trap.&lt;/p></description></item><item><title>Turn Your Broken Chatbot into Your Biggest Asset! ğŸ¦</title><link>https://louis-dupont.github.io/Blog/articles/leverage-chatbot/</link><pubDate>Sat, 28 Dec 2024 16:22:38 +0100</pubDate><guid>https://louis-dupont.github.io/Blog/articles/leverage-chatbot/</guid><description>&lt;p>You launched your chatbot, andâ€¦ well, itâ€™s not going as planned. Users are confused, workflows feel disjointed, and your teamâ€™s enthusiasm is quickly waning. Sound familiar?&lt;/p>
&lt;p>Hereâ€™s the good news: your chatbot isnâ€™t just failingâ€”itâ€™s revealing what matters.&lt;/p>
&lt;p>&lt;strong>Every awkward interaction or frustrated user is a clue&lt;/strong>. The gaps in your botâ€™s performance mirror the gaps in your understanding of user needs. And those gaps? Theyâ€™re opportunities.&lt;/p>
&lt;p>In my &lt;a href="the-chatbot-trap.md">recent post&lt;/a>, I explained why so many AI projects fall shortâ€”teams jump straight into building chatbots without asking whether theyâ€™re the right solution for the problem at hand. Often, theyâ€™re not. But even a â€œfailingâ€ chatbot can become a powerful diagnostic tool for understanding user needs more deeply.&lt;/p></description></item><item><title>ğŸ¤·â€â™‚ï¸ ModernBERT Is Here - and Itâ€™s Not Just Another LLM Update</title><link>https://louis-dupont.github.io/Blog/articles/modernbert/</link><pubDate>Fri, 20 Dec 2024 16:22:38 +0100</pubDate><guid>https://louis-dupont.github.io/Blog/articles/modernbert/</guid><description>&lt;p>BERT is back - and this time, itâ€™s &lt;strong>faster, smarter, and built for the tasks that matter.&lt;/strong>&lt;/p>
&lt;p>If youâ€™re working on &lt;strong>retrieval&lt;/strong>, &lt;strong>classification&lt;/strong>, or &lt;strong>code search&lt;/strong>, encoder models like BERT have likely been your go-to. Generative LLMs may grab headlines, but &lt;strong>when it comes to focused, production-ready AI tasks, BERT still shines&lt;/strong>.&lt;/p>
&lt;p>Earlier this year, I ran an experiment comparing models on a real-world taskâ€”analyzing product reviews. The results were eye-opening:&lt;/p></description></item><item><title/><link>https://louis-dupont.github.io/Blog/work-with-me/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://louis-dupont.github.io/Blog/work-with-me/</guid><description>&lt;p>AI teams donâ€™t struggle to build models. They struggle to improve them.&lt;/p>
&lt;p>Itâ€™s easy to tweak models, adjust prompts, optimize pipelines. But after a while, it stops being clear whether those changes are actually helping.&lt;/p>
&lt;p>AI doesnâ€™t improve simply by doing more. It improves when you have clarityâ€”when you &lt;strong>know exactly what&amp;rsquo;s limiting progress&lt;/strong>, and exactly how to move forward.&lt;/p>
&lt;p>That&amp;rsquo;s what I do.&lt;/p>
&lt;p>I help teams move &lt;strong>from guessing to a structured, systematic way of improving AI&lt;/strong>â€”one where every iteration is clear, measurable, and actually moves the needle.&lt;/p></description></item></channel></rss>