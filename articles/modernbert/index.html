<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>ü§∑‚Äç‚ôÇÔ∏è ModernBERT Is Here - and It‚Äôs Not Just Another LLM Update | Louis Dupont</title>
<meta name=keywords content><meta name=description content="BERT is back - and this time, it‚Äôs faster, smarter, and built for the tasks that matter.
If you‚Äôre working on retrieval, classification, or code search, encoder models like BERT have likely been your go-to. Generative LLMs may grab headlines, but when it comes to focused, production-ready AI tasks, BERT still shines.
Earlier this year, I ran an experiment comparing models on a real-world task‚Äîanalyzing product reviews. The results were eye-opening:"><meta name=author content="Louis Dupont"><link rel=canonical href=https://louis-dupont.github.io/Blog/articles/modernbert/><link crossorigin=anonymous href=/Blog/assets/css/stylesheet.45e028aa8ce0961349adf411b013ee39406be2c0bc80d4ea3fc04555f7f4611a.css integrity="sha256-ReAoqozglhNJrfQRsBPuOUBr4sC8gNTqP8BFVff0YRo=" rel="preload stylesheet" as=style><link rel=icon href=https://louis-dupont.github.io/Blog/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://louis-dupont.github.io/Blog/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://louis-dupont.github.io/Blog/favicon-32x32.png><link rel=apple-touch-icon href=https://louis-dupont.github.io/Blog/apple-touch-icon.png><link rel=mask-icon href=https://louis-dupont.github.io/Blog/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://louis-dupont.github.io/Blog/articles/modernbert/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><script async src="https://www.googletagmanager.com/gtag/js?id=G-GX2HR4QZL5"></script><script>var dnt,doNotTrack=!1;if(!1&&(dnt=navigator.doNotTrack||window.doNotTrack||navigator.msDoNotTrack,doNotTrack=dnt=="1"||dnt=="yes"),!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-GX2HR4QZL5")}</script><meta property="og:url" content="https://louis-dupont.github.io/Blog/articles/modernbert/"><meta property="og:site_name" content="Louis Dupont"><meta property="og:title" content="ü§∑‚Äç‚ôÇÔ∏è ModernBERT Is Here - and It‚Äôs Not Just Another LLM Update"><meta property="og:description" content="BERT is back - and this time, it‚Äôs faster, smarter, and built for the tasks that matter.
If you‚Äôre working on retrieval, classification, or code search, encoder models like BERT have likely been your go-to. Generative LLMs may grab headlines, but when it comes to focused, production-ready AI tasks, BERT still shines.
Earlier this year, I ran an experiment comparing models on a real-world task‚Äîanalyzing product reviews. The results were eye-opening:"><meta property="og:locale" content="en-us"><meta property="og:type" content="article"><meta property="article:section" content="articles"><meta property="article:published_time" content="2024-12-20T16:22:38+01:00"><meta property="article:modified_time" content="2024-12-20T16:22:38+01:00"><meta name=twitter:card content="summary"><meta name=twitter:title content="ü§∑‚Äç‚ôÇÔ∏è ModernBERT Is Here - and It‚Äôs Not Just Another LLM Update"><meta name=twitter:description content="BERT is back - and this time, it‚Äôs faster, smarter, and built for the tasks that matter.
If you‚Äôre working on retrieval, classification, or code search, encoder models like BERT have likely been your go-to. Generative LLMs may grab headlines, but when it comes to focused, production-ready AI tasks, BERT still shines.
Earlier this year, I ran an experiment comparing models on a real-world task‚Äîanalyzing product reviews. The results were eye-opening:"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Latest Insights on AI \u0026 LLM Development","item":"https://louis-dupont.github.io/Blog/articles/"},{"@type":"ListItem","position":2,"name":"ü§∑‚Äç‚ôÇÔ∏è ModernBERT Is Here - and It‚Äôs Not Just Another LLM Update","item":"https://louis-dupont.github.io/Blog/articles/modernbert/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"ü§∑‚Äç‚ôÇÔ∏è ModernBERT Is Here - and It‚Äôs Not Just Another LLM Update","name":"ü§∑‚Äç‚ôÇÔ∏è ModernBERT Is Here - and It‚Äôs Not Just Another LLM Update","description":"BERT is back - and this time, it‚Äôs faster, smarter, and built for the tasks that matter.\nIf you‚Äôre working on retrieval, classification, or code search, encoder models like BERT have likely been your go-to. Generative LLMs may grab headlines, but when it comes to focused, production-ready AI tasks, BERT still shines.\nEarlier this year, I ran an experiment comparing models on a real-world task‚Äîanalyzing product reviews. The results were eye-opening:\n","keywords":[],"articleBody":"BERT is back - and this time, it‚Äôs faster, smarter, and built for the tasks that matter.\nIf you‚Äôre working on retrieval, classification, or code search, encoder models like BERT have likely been your go-to. Generative LLMs may grab headlines, but when it comes to focused, production-ready AI tasks, BERT still shines.\nEarlier this year, I ran an experiment comparing models on a real-world task‚Äîanalyzing product reviews. The results were eye-opening:\nGPT-4o hit 91% accuracy with a cost of $1.40 per 1,000 reviews. After fine-tuning, Phi-3 mini matched GPT‚Äôs accuracy but ran locally, with 2.7 seconds per review. But the real surprise? 6-year-old BERT hit 97% accuracy, with processing speeds of just 0.03 seconds per review. This showed me that while LLMs excel at text generation and versatility, BERT dominates when you need precision and speed.\nWhy ModernBERT Is a Big Deal ModernBERT takes everything that made the original BERT great and levels it up:\n3x faster inference speeds. 8k token context length (vs. 512)‚Äîperfect for full-document retrieval. Trained on code, unlocking large-scale code search and smarter IDE tools. Generative models won‚Äôt replace what encoder models like BERT do best. If you‚Äôre building systems that need structured outputs, retrieval pipelines, or highly targeted classification, this release is worth your attention.\nAnd for the full details on ModernBERT: https://huggingface.co/blog/modernbert\n","wordCount":"218","inLanguage":"en","datePublished":"2024-12-20T16:22:38+01:00","dateModified":"2024-12-20T16:22:38+01:00","author":{"@type":"Person","name":"Louis Dupont"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://louis-dupont.github.io/Blog/articles/modernbert/"},"publisher":{"@type":"Organization","name":"Louis Dupont","logo":{"@type":"ImageObject","url":"https://louis-dupont.github.io/Blog/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://louis-dupont.github.io/Blog/ accesskey=h title="Louis Dupont (Alt + H)">Louis Dupont</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)" aria-label="Toggle theme"><svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://louis-dupont.github.io/Blog/ title=Home><span>Home</span></a></li><li><a href=https://louis-dupont.github.io/Blog/articles/ title=Articles><span>Articles</span></a></li><li><a href=https://louis-dupont.github.io/Blog/work-with-me/ title="Work with me"><span>Work with me</span></a></li></ul></nav></header><main class=main><article class=post-content><p style=display:none>Template: single.html</p><h1 class=post-title>ü§∑‚Äç‚ôÇÔ∏è ModernBERT Is Here - and It‚Äôs Not Just Another LLM Update</h1><p class=post-description></p><div class=post-body><p>BERT is back - and this time, it‚Äôs <strong>faster, smarter, and built for the tasks that matter.</strong></p><p>If you‚Äôre working on <strong>retrieval</strong>, <strong>classification</strong>, or <strong>code search</strong>, encoder models like BERT have likely been your go-to. Generative LLMs may grab headlines, but <strong>when it comes to focused, production-ready AI tasks, BERT still shines</strong>.</p><p>Earlier this year, I ran an experiment comparing models on a real-world task‚Äîanalyzing product reviews. The results were eye-opening:</p><ul><li>GPT-4o hit 91% accuracy with a cost of $1.40 per 1,000 reviews.</li><li>After fine-tuning, Phi-3 mini matched GPT‚Äôs accuracy but ran locally, with 2.7 seconds per review.</li><li>But the real surprise? <strong>6-year-old BERT</strong> hit <strong>97% accuracy</strong>, with processing speeds of just 0.03 seconds per review.</li></ul><p>This showed me that while LLMs excel at text generation and versatility, <strong>BERT dominates when you need precision and speed.</strong></p><h3 id=why-modernbert-is-a-big-deal>Why ModernBERT Is a Big Deal</h3><p>ModernBERT takes everything that made the original BERT great and levels it up:</p><ul><li><strong>3x faster inference speeds.</strong></li><li><strong>8k token context length</strong> (vs. 512)‚Äîperfect for full-document retrieval.</li><li><strong>Trained on code</strong>, unlocking large-scale code search and smarter IDE tools.</li></ul><p>Generative models won‚Äôt replace what encoder models like BERT do best. If you‚Äôre building systems that need structured outputs, retrieval pipelines, or highly targeted classification, this release is worth your attention.</p><p>And for the full details on ModernBERT: <a href=https://huggingface.co/blog/modernbert>https://huggingface.co/blog/modernbert</a></p></div></article></main><footer class=footer><span>&copy; 2025 <a href=https://louis-dupont.github.io/Blog/>Louis Dupont</a></span> ¬∑
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>