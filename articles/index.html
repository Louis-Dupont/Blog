<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Latest Insights on AI & LLM Development | Louis Dupont</title>
<meta name=keywords content><meta name=description content="Here, I share lessons from working with AI teams to improve their models systematically.
"><meta name=author content><link rel=canonical href=https://louis-dupont.github.io/Blog/articles/><link crossorigin=anonymous href=/Blog/assets/css/stylesheet.45e028aa8ce0961349adf411b013ee39406be2c0bc80d4ea3fc04555f7f4611a.css integrity="sha256-ReAoqozglhNJrfQRsBPuOUBr4sC8gNTqP8BFVff0YRo=" rel="preload stylesheet" as=style><link rel=icon href=https://louis-dupont.github.io/Blog/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://louis-dupont.github.io/Blog/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://louis-dupont.github.io/Blog/favicon-32x32.png><link rel=apple-touch-icon href=https://louis-dupont.github.io/Blog/apple-touch-icon.png><link rel=mask-icon href=https://louis-dupont.github.io/Blog/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate type=application/rss+xml href=https://louis-dupont.github.io/Blog/articles/index.xml><link rel=alternate hreflang=en href=https://louis-dupont.github.io/Blog/articles/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><script async src="https://www.googletagmanager.com/gtag/js?id=G-GX2HR4QZL5"></script><script>var dnt,doNotTrack=!1;if(!1&&(dnt=navigator.doNotTrack||window.doNotTrack||navigator.msDoNotTrack,doNotTrack=dnt=="1"||dnt=="yes"),!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-GX2HR4QZL5")}</script><meta property="og:url" content="https://louis-dupont.github.io/Blog/articles/"><meta property="og:site_name" content="Louis Dupont"><meta property="og:title" content="Latest Insights on AI & LLM Development"><meta property="og:description" content="Here, I share lessons from working with AI teams to improve their models systematically."><meta property="og:locale" content="en-us"><meta property="og:type" content="website"><meta name=twitter:card content="summary"><meta name=twitter:title content="Latest Insights on AI & LLM Development"><meta name=twitter:description content><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Latest Insights on AI \u0026 LLM Development","item":"https://louis-dupont.github.io/Blog/articles/"}]}</script></head><body class=list id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://louis-dupont.github.io/Blog/ accesskey=h title="Louis Dupont (Alt + H)">Louis Dupont</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)" aria-label="Toggle theme"><svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://louis-dupont.github.io/Blog/ title=Home><span>Home</span></a></li><li><a href=https://louis-dupont.github.io/Blog/articles/ title=Articles><span class=active>Articles</span></a></li><li><a href=https://louis-dupont.github.io/Blog/about/ title=About><span>About</span></a></li><li><a href=https://louis-dupont.github.io/Blog/contact/ title=Contact><span>Contact</span></a></li></ul></nav></header><main class=main><header class=page-header><h1>Latest Insights on AI & LLM Development</h1></header><div class=post-content><p>Here, I share lessons from working with AI teams to improve their models systematically.</p><hr></div><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>ğŸª¤ The Chatbot Trap - Why Your LLM Project Is Stuck After the â€œWow Moment"</h2></header><div class=entry-content><p>Your LLM prototype amazed everyoneâ€”until it didnâ€™t. Now itâ€™s stuck, and no oneâ€™s using it. Hereâ€™s why.
When most companies experiment with AI, the go-to application is a chatbot. Itâ€™s intuitive, it looks impressive, and it feels like magic. But hereâ€™s the cold, hard truth: chatbots are why most LLM projects fail.
Iâ€™ve seen it happen countless times. The team builds a chatbot to â€œharness AI,â€ and at first, it wows everyone. But then the cracks start to show:
...</p></div><footer class=entry-footer><span title='2025-03-07 16:22:38 +0100 +0100'>March 7, 2025</span>&nbsp;Â·&nbsp;5 min</footer><a class=entry-link aria-label='post link to ğŸª¤ The Chatbot Trap - Why Your LLM Project Is Stuck After the â€œWow Moment"' href=https://louis-dupont.github.io/Blog/articles/the-chatbot-trap/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>DO NOT use these LLM Metrics â›” And what to do instead!</h2></header><div class=entry-content><p>In two words: Generalist LLM metrics are more of a danger than an opportunity.
NEVER start with them. Use them only as a last resortâ€”and even then, with strict guidelines! So what are these vague, generic metrics? Helpfulness Conciseness Tone Personalisation â€¦ and more! But whatâ€™s so wrong with them?
These Metrics Lack Real Meaning The biggest problem? Theyâ€™re designed to evaluate an LLM in general, not a specific use case.
...</p></div><footer class=entry-footer><span title='2025-02-15 11:00:00 +0100 +0100'>February 15, 2025</span>&nbsp;Â·&nbsp;1 min</footer><a class=entry-link aria-label="post link to DO NOT use these LLM Metrics â›” And what to do instead!" href=https://louis-dupont.github.io/Blog/articles/eval-metrics-to-avoid/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>Error Analysis ğŸ”§ Stop Guessing, Start Fixing AI Models</h2></header><div class=entry-content><p>Error analysis is about digging deep into why something isnâ€™t working - to learn from it. It might sound obvious, but itâ€™s shockingly underused, especially where it matters most: AI development.
Letâ€™s explore what it is through an example
Cats or Dogs ? Iâ€™m skipping many details that may hurt Data Scientists for the sake of simplicity.
Say you have 200 images to classify as either cats or dogs. You build an AI and get 78% accuracy - not great. We need to do better. But how?
...</p></div><footer class=entry-footer><span title='2025-02-14 12:00:00 +0100 +0100'>February 14, 2025</span>&nbsp;Â·&nbsp;2 min</footer><a class=entry-link aria-label="post link to Error Analysis ğŸ”§ Stop Guessing, Start Fixing AI Models" href=https://louis-dupont.github.io/Blog/articles/error-analys-intro/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>Evaluate your LLM! Ok, but what's next? ğŸ¤”</h2></header><div class=entry-content><p>Everyone say you need to Evaluate your LLM. You just did it. Now what? ğŸ¤·â€â™‚ï¸
You got a score. Great. Now, hereâ€™s the trap:
You either:
Trust it. (â€œNice, letâ€™s ship!â€) Chase a better one. (â€œTweak some stuff and re-run!â€) Both are horrible ideas.
Step 1: Stop staring at numbers. Numbers feel scientific, but they lie all the time.
Before doing anything, look at actual examples. Whatâ€™s failing?
Bad output? Fix the model. Good output but bad score? Fix the eval. Both wrong? Youâ€™ve got bigger problems. Step 2: Solve the right problem. If your model sucks, tweak:
...</p></div><footer class=entry-footer><span title='2025-01-02 10:00:00 +0100 +0100'>January 2, 2025</span>&nbsp;Â·&nbsp;1 min</footer><a class=entry-link aria-label="post link to Evaluate your LLM! Ok, but what's next? ğŸ¤”" href=https://louis-dupont.github.io/Blog/articles/evaluate-chatbot-whatnext/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>LLM Evals - The Trap No Oneâ€™s Telling You ğŸ”</h2></header><div class=entry-content><p>We hear it more and more: â€˜Use LLM Evaluations to guide your AI project.â€™ And for a good reasonâ€”metrics are essential.
Yet, thereâ€™s a trap nobody talks aboutâ€¦
Letâ€™s say you have a chatbot and want to introduce metrics. You find tools that compute metrics like â€˜Helpfulnessâ€™, â€˜Concisenessâ€™, and â€˜Completenessâ€™. Sounds greatâ€”they promise to optimise your userâ€™s experience. Right?
Truth is, their correlation to real business value is often unclear. Is this really what your user cares about ? Will this increase adoption ?
...</p></div><footer class=entry-footer><span title='2025-01-02 10:00:00 +0100 +0100'>January 2, 2025</span>&nbsp;Â·&nbsp;1 min</footer><a class=entry-link aria-label="post link to LLM Evals - The Trap No Oneâ€™s Telling You ğŸ”" href=https://louis-dupont.github.io/Blog/articles/eval-trap/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>ğŸ“‰ Why Improving Your AI Model Is Killing Your Projectâ€™s Success</h2></header><div class=entry-content><p>What if improving your AI model is the very thing holding your project back?
Youâ€™ve spent weeks fine-tuning itâ€”polishing every detail, boosting accuracy, solving edge cases. Yet, adoption hasnâ€™t moved. Frustrating? Youâ€™re not aloneâ€”this is a trap many AI teams fall into.
The problem isnâ€™t that AI isnâ€™t ready. Itâ€™s that the way we approach AI makes us feel productive while ignoring the real challenge: solving critical user needs.
Letâ€™s break down why this happensâ€”and how you can escape the trap.
...</p></div><footer class=entry-footer><span title='2025-01-01 16:22:38 +0100 +0100'>January 1, 2025</span>&nbsp;Â·&nbsp;4 min</footer><a class=entry-link aria-label="post link to ğŸ“‰ Why Improving Your AI Model Is Killing Your Projectâ€™s Success" href=https://louis-dupont.github.io/Blog/articles/dont-improve-ai/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>Turn Your Broken Chatbot into Your Biggest Asset! ğŸ¦</h2></header><div class=entry-content><p>You launched your chatbot, andâ€¦ well, itâ€™s not going as planned. Users are confused, workflows feel disjointed, and your teamâ€™s enthusiasm is quickly waning. Sound familiar?
Hereâ€™s the good news: your chatbot isnâ€™t just failingâ€”itâ€™s revealing what matters.
Every awkward interaction or frustrated user is a clue. The gaps in your botâ€™s performance mirror the gaps in your understanding of user needs. And those gaps? Theyâ€™re opportunities.
In my recent post, I explained why so many AI projects fall shortâ€”teams jump straight into building chatbots without asking whether theyâ€™re the right solution for the problem at hand. Often, theyâ€™re not. But even a â€œfailingâ€ chatbot can become a powerful diagnostic tool for understanding user needs more deeply.
...</p></div><footer class=entry-footer><span title='2024-12-28 16:22:38 +0100 +0100'>December 28, 2024</span>&nbsp;Â·&nbsp;4 min</footer><a class=entry-link aria-label="post link to Turn Your Broken Chatbot into Your Biggest Asset! ğŸ¦" href=https://louis-dupont.github.io/Blog/articles/leverage-chatbot/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>ğŸ¤·â€â™‚ï¸ ModernBERT Is Here - and Itâ€™s Not Just Another LLM Update</h2></header><div class=entry-content><p>BERT is back - and this time, itâ€™s faster, smarter, and built for the tasks that matter.
If youâ€™re working on retrieval, classification, or code search, encoder models like BERT have likely been your go-to. Generative LLMs may grab headlines, but when it comes to focused, production-ready AI tasks, BERT still shines.
Earlier this year, I ran an experiment comparing models on a real-world taskâ€”analyzing product reviews. The results were eye-opening:
...</p></div><footer class=entry-footer><span title='2024-12-20 16:22:38 +0100 +0100'>December 20, 2024</span>&nbsp;Â·&nbsp;2 min</footer><a class=entry-link aria-label="post link to ğŸ¤·â€â™‚ï¸ ModernBERT Is Here - and Itâ€™s Not Just Another LLM Update" href=https://louis-dupont.github.io/Blog/articles/modernbert/></a></article></main><footer class=footer><span>&copy; 2025 <a href=https://louis-dupont.github.io/Blog/>Louis Dupont</a></span> Â·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>