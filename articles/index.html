<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Latest Insights on AI & LLM Development | Louis Dupont</title>
<meta name=keywords content><meta name=description content="Here, I share lessons from working with AI teams to improve their models systematically.
"><meta name=author content><link rel=canonical href=https://louis-dupont.github.io/Blog/articles/><link crossorigin=anonymous href=/Blog/assets/css/stylesheet.45e028aa8ce0961349adf411b013ee39406be2c0bc80d4ea3fc04555f7f4611a.css integrity="sha256-ReAoqozglhNJrfQRsBPuOUBr4sC8gNTqP8BFVff0YRo=" rel="preload stylesheet" as=style><link rel=icon href=https://louis-dupont.github.io/Blog/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://louis-dupont.github.io/Blog/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://louis-dupont.github.io/Blog/favicon-32x32.png><link rel=apple-touch-icon href=https://louis-dupont.github.io/Blog/apple-touch-icon.png><link rel=mask-icon href=https://louis-dupont.github.io/Blog/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate type=application/rss+xml href=https://louis-dupont.github.io/Blog/articles/index.xml><link rel=alternate hreflang=en href=https://louis-dupont.github.io/Blog/articles/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><script async src="https://www.googletagmanager.com/gtag/js?id=G-GX2HR4QZL5"></script><script>var dnt,doNotTrack=!1;if(!1&&(dnt=navigator.doNotTrack||window.doNotTrack||navigator.msDoNotTrack,doNotTrack=dnt=="1"||dnt=="yes"),!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-GX2HR4QZL5")}</script><meta property="og:url" content="https://louis-dupont.github.io/Blog/articles/"><meta property="og:site_name" content="Louis Dupont"><meta property="og:title" content="Latest Insights on AI & LLM Development"><meta property="og:description" content="Here, I share lessons from working with AI teams to improve their models systematically."><meta property="og:locale" content="en-us"><meta property="og:type" content="website"><meta name=twitter:card content="summary"><meta name=twitter:title content="Latest Insights on AI & LLM Development"><meta name=twitter:description content><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Latest Insights on AI \u0026 LLM Development","item":"https://louis-dupont.github.io/Blog/articles/"}]}</script></head><body class=list id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://louis-dupont.github.io/Blog/ accesskey=h title="Louis Dupont (Alt + H)">Louis Dupont</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)" aria-label="Toggle theme"><svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://louis-dupont.github.io/Blog/ title=Home><span>Home</span></a></li><li><a href=https://louis-dupont.github.io/Blog/articles/ title=Articles><span class=active>Articles</span></a></li><li><a href=https://louis-dupont.github.io/Blog/about/ title=About><span>About</span></a></li><li><a href=https://louis-dupont.github.io/Blog/contact/ title=Contact><span>Contact</span></a></li></ul></nav></header><main class=main><header class=page-header><h1>Latest Insights on AI & LLM Development</h1></header><div class=post-content><p>Here, I share lessons from working with AI teams to improve their models systematically.</p><hr></div><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>🪤 The Chatbot Trap - Why Your LLM Project Is Stuck After the “Wow Moment"</h2></header><div class=entry-content><p>Your LLM prototype amazed everyone—until it didn’t. Now it’s stuck, and no one’s using it. Here’s why.
When most companies experiment with AI, the go-to application is a chatbot. It’s intuitive, it looks impressive, and it feels like magic. But here’s the cold, hard truth: chatbots are why most LLM projects fail.
I’ve seen it happen countless times. The team builds a chatbot to “harness AI,” and at first, it wows everyone. But then the cracks start to show:
...</p></div><footer class=entry-footer><span title='2025-03-07 16:22:38 +0100 +0100'>March 7, 2025</span>&nbsp;·&nbsp;5 min</footer><a class=entry-link aria-label='post link to 🪤 The Chatbot Trap - Why Your LLM Project Is Stuck After the “Wow Moment"' href=https://louis-dupont.github.io/Blog/articles/the-chatbot-trap/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>DO NOT use these LLM Metrics ⛔ And what to do instead!</h2></header><div class=entry-content><p>In two words: Generalist LLM metrics are more of a danger than an opportunity.
NEVER start with them. Use them only as a last resort—and even then, with strict guidelines! So what are these vague, generic metrics? Helpfulness Conciseness Tone Personalisation … and more! But what’s so wrong with them?
These Metrics Lack Real Meaning The biggest problem? They’re designed to evaluate an LLM in general, not a specific use case.
...</p></div><footer class=entry-footer><span title='2025-02-15 11:00:00 +0100 +0100'>February 15, 2025</span>&nbsp;·&nbsp;1 min</footer><a class=entry-link aria-label="post link to DO NOT use these LLM Metrics ⛔ And what to do instead!" href=https://louis-dupont.github.io/Blog/articles/eval-metrics-to-avoid/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>Error Analysis 🔧 Stop Guessing, Start Fixing AI Models</h2></header><div class=entry-content><p>Error analysis is about digging deep into why something isn’t working - to learn from it. It might sound obvious, but it’s shockingly underused, especially where it matters most: AI development.
Let’s explore what it is through an example
Cats or Dogs ? I’m skipping many details that may hurt Data Scientists for the sake of simplicity.
Say you have 200 images to classify as either cats or dogs. You build an AI and get 78% accuracy - not great. We need to do better. But how?
...</p></div><footer class=entry-footer><span title='2025-02-14 12:00:00 +0100 +0100'>February 14, 2025</span>&nbsp;·&nbsp;2 min</footer><a class=entry-link aria-label="post link to Error Analysis 🔧 Stop Guessing, Start Fixing AI Models" href=https://louis-dupont.github.io/Blog/articles/error-analys-intro/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>Evaluate your LLM! Ok, but what's next? 🤔</h2></header><div class=entry-content><p>Everyone say you need to Evaluate your LLM. You just did it. Now what? 🤷‍♂️
You got a score. Great. Now, here’s the trap:
You either:
Trust it. (“Nice, let’s ship!”) Chase a better one. (“Tweak some stuff and re-run!”) Both are horrible ideas.
Step 1: Stop staring at numbers. Numbers feel scientific, but they lie all the time.
Before doing anything, look at actual examples. What’s failing?
Bad output? Fix the model. Good output but bad score? Fix the eval. Both wrong? You’ve got bigger problems. Step 2: Solve the right problem. If your model sucks, tweak:
...</p></div><footer class=entry-footer><span title='2025-01-02 10:00:00 +0100 +0100'>January 2, 2025</span>&nbsp;·&nbsp;1 min</footer><a class=entry-link aria-label="post link to Evaluate your LLM! Ok, but what's next? 🤔" href=https://louis-dupont.github.io/Blog/articles/evaluate-chatbot-whatnext/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>LLM Evals - The Trap No One’s Telling You 🐔</h2></header><div class=entry-content><p>We hear it more and more: ‘Use LLM Evaluations to guide your AI project.’ And for a good reason—metrics are essential.
Yet, there’s a trap nobody talks about…
Let’s say you have a chatbot and want to introduce metrics. You find tools that compute metrics like ‘Helpfulness’, ‘Conciseness’, and ‘Completeness’. Sounds great—they promise to optimise your user’s experience. Right?
Truth is, their correlation to real business value is often unclear. Is this really what your user cares about ? Will this increase adoption ?
...</p></div><footer class=entry-footer><span title='2025-01-02 10:00:00 +0100 +0100'>January 2, 2025</span>&nbsp;·&nbsp;1 min</footer><a class=entry-link aria-label="post link to LLM Evals - The Trap No One’s Telling You 🐔" href=https://louis-dupont.github.io/Blog/articles/eval-trap/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>📉 Why Improving Your AI Model Is Killing Your Project’s Success</h2></header><div class=entry-content><p>What if improving your AI model is the very thing holding your project back?
You’ve spent weeks fine-tuning it—polishing every detail, boosting accuracy, solving edge cases. Yet, adoption hasn’t moved. Frustrating? You’re not alone—this is a trap many AI teams fall into.
The problem isn’t that AI isn’t ready. It’s that the way we approach AI makes us feel productive while ignoring the real challenge: solving critical user needs.
Let’s break down why this happens—and how you can escape the trap.
...</p></div><footer class=entry-footer><span title='2025-01-01 16:22:38 +0100 +0100'>January 1, 2025</span>&nbsp;·&nbsp;4 min</footer><a class=entry-link aria-label="post link to 📉 Why Improving Your AI Model Is Killing Your Project’s Success" href=https://louis-dupont.github.io/Blog/articles/dont-improve-ai/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>Turn Your Broken Chatbot into Your Biggest Asset! 🏦</h2></header><div class=entry-content><p>You launched your chatbot, and… well, it’s not going as planned. Users are confused, workflows feel disjointed, and your team’s enthusiasm is quickly waning. Sound familiar?
Here’s the good news: your chatbot isn’t just failing—it’s revealing what matters.
Every awkward interaction or frustrated user is a clue. The gaps in your bot’s performance mirror the gaps in your understanding of user needs. And those gaps? They’re opportunities.
In my recent post, I explained why so many AI projects fall short—teams jump straight into building chatbots without asking whether they’re the right solution for the problem at hand. Often, they’re not. But even a “failing” chatbot can become a powerful diagnostic tool for understanding user needs more deeply.
...</p></div><footer class=entry-footer><span title='2024-12-28 16:22:38 +0100 +0100'>December 28, 2024</span>&nbsp;·&nbsp;4 min</footer><a class=entry-link aria-label="post link to Turn Your Broken Chatbot into Your Biggest Asset! 🏦" href=https://louis-dupont.github.io/Blog/articles/leverage-chatbot/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>🤷‍♂️ ModernBERT Is Here - and It’s Not Just Another LLM Update</h2></header><div class=entry-content><p>BERT is back - and this time, it’s faster, smarter, and built for the tasks that matter.
If you’re working on retrieval, classification, or code search, encoder models like BERT have likely been your go-to. Generative LLMs may grab headlines, but when it comes to focused, production-ready AI tasks, BERT still shines.
Earlier this year, I ran an experiment comparing models on a real-world task—analyzing product reviews. The results were eye-opening:
...</p></div><footer class=entry-footer><span title='2024-12-20 16:22:38 +0100 +0100'>December 20, 2024</span>&nbsp;·&nbsp;2 min</footer><a class=entry-link aria-label="post link to 🤷‍♂️ ModernBERT Is Here - and It’s Not Just Another LLM Update" href=https://louis-dupont.github.io/Blog/articles/modernbert/></a></article></main><footer class=footer><span>&copy; 2025 <a href=https://louis-dupont.github.io/Blog/>Louis Dupont</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>