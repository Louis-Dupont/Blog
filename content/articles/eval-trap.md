+++
date = '2025-01-02T10:00:00+01:00'
draft = false
title = "LLM Evals - The Trap No One's Telling You 🐔"
+++

We hear it more and more: ‘Use LLM Evaluations to guide your AI project.' And for a good reason—metrics are essential.

**Yet, there's a trap nobody talks about...**

Let's say you have a chatbot and want to introduce metrics. You find tools that compute metrics like 'Helpfulness', 'Conciseness', and 'Completeness'.
Sounds great—they promise to optimise your user's experience. Right?

Truth is, their correlation to real business value is often unclear. Is this really what your user cares about ? Will this increase adoption ?

Many teams end up measuring the wrong thing, thinking they're being data-driven, while forgetting about what really matters.

Metrics aren't inherently good. They're only as useful as the questions they help you answer.

_If you don't ask ‘What does success look like?' or ‘What is the goal I want to measure?' your metrics aren't leading you—they're misleading you._

So, the next time you set metrics, ask yourself: Are you measuring what impacts your business goals—or just what's easy to quantify?

**The difference might explain why your AI project feels stuck.**

_Because chasing the wrong metrics isn't progress. It's running in circles—like a headless chicken._

<!-- ![Evaluation Trap](https://dev-to-uploads.s3.amazonaws.com/uploads/articles/nu3m9w2k4jie443v2085.jpg) -->
