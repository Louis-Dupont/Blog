---
title: "Work With Me"
description: "AI doesn't improve by doing more. It improves when you have clarity—when you know exactly what's holding you back, and exactly how to move forward. That's what I help with."
date: 2024-05-20
---

Most teams building with LLMs hit the same wall.

At first, things move fast. You get that early “wow effect.” You tweak prompts, change the pipeline, test a few retrieval tricks—and the output gets better.

But eventually, you’re not sure if anything’s actually improving anymore.

Some answers are clearly better.  
Some aren’t.  
And you can’t really tell if the system is getting stronger—or just different.

That’s the real bottleneck.  
Not your model. Not your stack.  
It’s the ability to know what’s actually working, what’s not, and what to do next.

That’s where I help.

---

When I work with teams, it’s not about running more experiments.  
It’s about making sure those experiments _mean something_.

We start by getting clarity. What’s actually slowing you down? What failure modes keep recurring? What’s driving real quality—and what’s just noise?

Once we have that, we build structure. Lightweight, human-first methods that help you see clearly and iterate deliberately. Think: error analysis, segmentation, evaluation scaffolding—nothing fancy, just the right lens for the right moment.

And then we move.  
Not with vibes, not with guesses.  
But with visibility.

---

If you’re still circling the problem, feel free to dive into the [**blog**](../articles/). That’s where I break down the core ideas behind all of this.

If you're already working on something and want a quick outside perspective, I keep one slot open each week for a free office hour. No prep needed—just context and a real question. You can [**request a spot here**](https://form.typeform.com/to/VQqJ2ZDT).

And if it feels like you need something more hands-on, that’s possible too. But it always starts the same way: we take a proper look together.

[Here’s how that works →](../diagnostic)
